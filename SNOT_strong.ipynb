{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking Strong Neural Optimal Transport (SNOT)\n",
    "\n",
    "This notebook collects notebooks from *\"stacking_notebooks\"* folder \n",
    "in one place.\n",
    "\n",
    "It was implemented with manual selection of the weights for the prediction with preferable FID-metric of the previous stacking stage."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "# sys.path.append(\"..\")\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import gc\n",
    "\n",
    "from src import distributions\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from src.resnet2 import ResNet_D\n",
    "from src.unet import UNet\n",
    "\n",
    "from src.tools import unfreeze, freeze\n",
    "from src.tools import weights_init_D\n",
    "from src.tools import load_dataset, get_pushed_loader_stats\n",
    "from src.fid_score import calculate_frechet_distance\n",
    "from src.plotters import plot_random_images, plot_images\n",
    "\n",
    "# Module for saving and loading data from previous stacking step\n",
    "from src.transform_save_load import transform_data, new_sample_the_same\n",
    "\n",
    "from copy import deepcopy\n",
    "import json\n",
    "\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import wandb # <--- online logging of the results\n",
    "from src.tools import fig2data, fig2img # for wandb\n",
    "\n",
    "# This needed to use dataloaders for some datasets\n",
    "from PIL import PngImagePlugin\n",
    "LARGE_ENOUGH_NUMBER = 100\n",
    "PngImagePlugin.MAX_TEXT_CHUNK = LARGE_ENOUGH_NUMBER * (1024**2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Config\n",
    "\n",
    "In case of uniform model parameters during stacking steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE_IDS = [0]\n",
    "\n",
    "DATASET1 = 'handbag' # Path will be different from stage to stage\n",
    "\n",
    "# Target (Always the same)\n",
    "DATASET2  = 'shoes'\n",
    "DATASET2_PATH = 'data/shoes_64.hdf5'\n",
    "\n",
    "IMG_SIZE = 64\n",
    "\n",
    "T_ITERS = 10\n",
    "f_LR, T_LR = 1e-4, 1e-4\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "PLOT_INTERVAL = 100\n",
    "COST = 'mse' # Mean Squared Error\n",
    "CPKT_INTERVAL = 500\n",
    "\n",
    "SEED = 0x000000"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    DATASET1=DATASET1,\n",
    "    DATASET2=DATASET2, \n",
    "    T_ITERS=T_ITERS,\n",
    "    f_LR=f_LR, T_LR=T_LR,\n",
    "    BATCH_SIZE=BATCH_SIZE\n",
    ")\n",
    "    \n",
    "assert torch.cuda.is_available()\n",
    "torch.cuda.set_device(f'cuda:{DEVICE_IDS[0]}')\n",
    "torch.manual_seed(SEED); np.random.seed(SEED)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data stats for testing\n",
    "This stats data should be on the root folder \"data\". It can be created by [compute_stats.ipynb](https://github.com/iamalexkorotin/NeuralOptimalTransport/blob/main/stats/compute_stats.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always the same\n",
    "filename = 'data/{}_{}_test.json'.format(DATASET2, IMG_SIZE)\n",
    "with open(filename, 'r') as fp:\n",
    "    data_stats = json.load(fp)\n",
    "    mu_data, sigma_data = data_stats['mu'], data_stats['sigma']\n",
    "del data_stats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Samplers Y\n",
    "They will not change during stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always the same\n",
    "Y_sampler, Y_test_sampler = load_dataset(DATASET2, DATASET2_PATH, img_size=IMG_SIZE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training function\n",
    "\n",
    "Same commands for all stacking steps, \n",
    "thus for making this notebook more compact these commands were combined \n",
    "in one function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training():\n",
    "    \"\"\"Training function for all stacking steps.\n",
    "    Initialize MAX_STEPS, OUTPUT_PATH, T, f, T_opt, f_opt, \n",
    "    X_sampler, X_fixed, Y_fixed, X_test_fixed, Y_test_fixed, X_test_sampler, \n",
    "    Y_test_sampler before launching this function!\n",
    "    \"\"\"\n",
    "    for step in tqdm(range(MAX_STEPS)):\n",
    "        # T optimization\n",
    "        unfreeze(T); freeze(f)\n",
    "        for t_iter in range(T_ITERS): \n",
    "            T_opt.zero_grad()\n",
    "            X = X_sampler.sample(BATCH_SIZE)\n",
    "            T_X = T(X)\n",
    "            if COST == 'mse':\n",
    "                T_loss = F.mse_loss(X, T_X).mean() - f(T_X).mean()\n",
    "            else:\n",
    "                raise Exception('Unknown COST')\n",
    "            T_loss.backward(); T_opt.step()\n",
    "        del T_loss, T_X, X; gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "        # f optimization\n",
    "        freeze(T); unfreeze(f)\n",
    "        X = X_sampler.sample(BATCH_SIZE)\n",
    "        with torch.no_grad():\n",
    "            T_X = T(X)\n",
    "        Y = Y_sampler.sample(BATCH_SIZE)\n",
    "        f_opt.zero_grad()\n",
    "        f_loss = f(T_X).mean() - f(Y).mean()\n",
    "        f_loss.backward(); f_opt.step();\n",
    "        wandb.log({f'f_loss' : f_loss.item()}, step=step) \n",
    "        del f_loss, Y, X, T_X; gc.collect(); torch.cuda.empty_cache()\n",
    "            \n",
    "        if step % PLOT_INTERVAL == 0:\n",
    "            print('Plotting')\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            fig, axes = plot_images(X_fixed, Y_fixed, T)\n",
    "            wandb.log({'Fixed Images' : [wandb.Image(fig2img(fig))]}, \n",
    "                      step=step) \n",
    "            plt.show(fig); plt.close(fig) \n",
    "            \n",
    "            fig, axes = plot_random_images(X_sampler,  Y_sampler, T)\n",
    "            wandb.log({'Random Images' : [wandb.Image(fig2img(fig))]}, \n",
    "                      step=step) \n",
    "            plt.show(fig); plt.close(fig) \n",
    "            \n",
    "            fig, axes = plot_images(X_test_fixed, Y_test_fixed, T)\n",
    "            wandb.log({'Fixed Test Images' : [wandb.Image(fig2img(fig))]}, \n",
    "                      step=step) \n",
    "            plt.show(fig); plt.close(fig) \n",
    "            \n",
    "            fig, axes = plot_random_images(X_test_sampler, Y_test_sampler, T)\n",
    "            wandb.log({'Random Test Images' : [wandb.Image(fig2img(fig))]}, \n",
    "                      step=step) \n",
    "            plt.show(fig); plt.close(fig) \n",
    "        \n",
    "        if step % CPKT_INTERVAL == CPKT_INTERVAL - 1:\n",
    "            freeze(T); \n",
    "            \n",
    "            print('Computing FID')\n",
    "            mu, sigma = get_pushed_loader_stats(T, X_test_sampler.loader)\n",
    "            fid = calculate_frechet_distance(mu_data, sigma_data, mu, sigma)\n",
    "            wandb.log({f'FID (Test)' : fid}, step=step)\n",
    "            del mu, sigma\n",
    "            \n",
    "            torch.save(T.state_dict(), \n",
    "                       os.path.join(OUTPUT_PATH, f'{SEED}_{step}.pt'))\n",
    "            torch.save(f.state_dict(), \n",
    "                       os.path.join(OUTPUT_PATH, f'f_{SEED}_{step}.pt'))\n",
    "            torch.save(f_opt.state_dict(), \n",
    "                       os.path.join(OUTPUT_PATH, f'f_opt_{SEED}_{step}.pt'))\n",
    "            torch.save(T_opt.state_dict(), \n",
    "                       os.path.join(OUTPUT_PATH, f'T_opt_{SEED}_{step}.pt'))\n",
    "        \n",
    "        gc.collect(); torch.cuda.empty_cache()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking #0\n",
    "\n",
    "This is a modified baseline of [NOT_strong](https://github.com/iamalexkorotin/NeuralOptimalTransport/blob/main/notebooks/NOT_training_strong.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STAGE = 0\n",
    "\n",
    "DATASET1_SOURCE_PATH = 'data/handbag_64.hdf5'\n",
    "\n",
    "MAX_STEPS = 1001 # for testing one-notebook solution, default = 100_001\n",
    "\n",
    "EXP_NAME = f'_{DATASET1}_{DATASET2}_T{T_ITERS}_{COST}_{IMG_SIZE}_S{STAGE}'\n",
    "OUTPUT_PATH = f'checkpoints/{COST}/{DATASET1}_{DATASET2}_{IMG_SIZE}/stage_{STAGE}'\n",
    "\n",
    "if not os.path.exists(OUTPUT_PATH):\n",
    "    os.makedirs(OUTPUT_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Sampler X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sampler, X_test_sampler = load_dataset(DATASET1, DATASET1_SOURCE_PATH, \n",
    "                                         img_size=IMG_SIZE)\n",
    "    \n",
    "torch.cuda.empty_cache(); gc.collect()\n",
    "# clear_output()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = ResNet_D(IMG_SIZE, nc=3).cuda()\n",
    "f.apply(weights_init_D)\n",
    "\n",
    "T = UNet(3, 3, base_factor=48).cuda()\n",
    "\n",
    "if len(DEVICE_IDS) > 1:\n",
    "    T = nn.DataParallel(T, device_ids=DEVICE_IDS)\n",
    "    f = nn.DataParallel(f, device_ids=DEVICE_IDS)\n",
    "    \n",
    "print('T params:', np.sum([np.prod(p.shape) for p in T.parameters()]))\n",
    "print('f params:', np.sum([np.prod(p.shape) for p in f.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0xBADBEEF); np.random.seed(0xBADBEEF)\n",
    "X_fixed = X_sampler.sample(10)\n",
    "Y_fixed = Y_sampler.sample(10)\n",
    "X_test_fixed = X_test_sampler.sample(10)\n",
    "Y_test_fixed = Y_test_sampler.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plot_images(X_fixed, Y_fixed, T)\n",
    "fig, axes = plot_random_images(X_sampler, Y_sampler, T)\n",
    "fig, axes = plot_images(X_test_fixed, Y_test_fixed, T)\n",
    "fig, axes = plot_random_images(X_test_sampler, Y_test_sampler, T)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(name=EXP_NAME, project='snot', entity='dstech', config=config)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_opt = torch.optim.Adam(T.parameters(), lr=T_LR, weight_decay=1e-10)\n",
    "f_opt = torch.optim.Adam(f.parameters(), lr=f_LR, weight_decay=1e-10)\n",
    "\n",
    "training()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finish experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finish experiment\n",
    "gc.collect(); torch.cuda.empty_cache()\n",
    "wandb.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking #1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make prediction\n",
    "\n",
    "According to obtained FID-metric choose preferable step (for example, with minimal FID-metric) and save weights *\"0_[preferable step].pt*\" from checkpoints as *\"best_weights/stage_[STAGE].pt\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STAGE = 1\n",
    "\n",
    "# Only for stage 1, before getting the prediction\n",
    "DATASET1_SOURCE_PATH = 'data/handbag_64.hdf5'\n",
    "\n",
    "# Path for getting the best weights from last stage\n",
    "BEST_WEIGHTS_PATH = f'best_weights/stage_{STAGE-1}.pt'\n",
    "\n",
    "# Path for saving prediction images by the previous stage\n",
    "# and for loading from them for the current stage\n",
    "DATASET1_TRAIN_PATH = f'data/handbag_64_train_stage_{STAGE}.pt'\n",
    "DATASET1_TEST_PATH = f'data/handbag_64_test_stage_{STAGE}.pt'\n",
    "\n",
    "MAX_STEPS = 501 # for testing one-notebook solution, default = 30_001\n",
    "\n",
    "EXP_NAME = f'_{DATASET1}_{DATASET2}_T{T_ITERS}_{COST}_{IMG_SIZE}_S{STAGE}'\n",
    "OUTPUT_PATH = f'checkpoints/{COST}/{DATASET1}_{DATASET2}_{IMG_SIZE}/stage_{STAGE}'\n",
    "\n",
    "if not os.path.exists(OUTPUT_PATH):\n",
    "    os.makedirs(OUTPUT_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Previous Sampler X, if it is not on the RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Only for the stage 1\n",
    "# X_sampler, X_test_sampler = load_dataset(DATASET1, \n",
    "#                             DATASET1_SOURCE_PATH, img_size=IMG_SIZE)\n",
    "\n",
    "# torch.cuda.empty_cache(); gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up T(X) on best weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = UNet(3, 3, base_factor=48)\n",
    "\n",
    "print('T params:', np.sum([np.prod(p.shape) for p in T.parameters()]))\n",
    "\n",
    "# Setup earlier params\n",
    "T.load_state_dict(torch.load(BEST_WEIGHTS_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on best T(X) for train and test, and save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_data(X_sampler, DATASET1_TRAIN_PATH, T)\n",
    "del X_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_data(X_test_sampler, DATASET1_TEST_PATH, T)\n",
    "del X_test_sampler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare New Samplers X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sampler = new_sample_the_same(DATASET1_TRAIN_PATH, shuffle=True)\n",
    "X_test_sampler = new_sample_the_same(DATASET1_TEST_PATH)\n",
    "\n",
    "torch.cuda.empty_cache(); gc.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = ResNet_D(IMG_SIZE, nc=3).cuda()\n",
    "f.apply(weights_init_D)\n",
    "\n",
    "T = UNet(3, 3, base_factor=48).cuda()\n",
    "\n",
    "if len(DEVICE_IDS) > 1:\n",
    "    T = nn.DataParallel(T, device_ids=DEVICE_IDS)\n",
    "    f = nn.DataParallel(f, device_ids=DEVICE_IDS)\n",
    "    \n",
    "print('T params:', np.sum([np.prod(p.shape) for p in T.parameters()]))\n",
    "print('f params:', np.sum([np.prod(p.shape) for p in f.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0xBADBEEF); np.random.seed(0xBADBEEF)\n",
    "X_fixed = X_sampler.sample(10)\n",
    "Y_fixed = Y_sampler.sample(10)\n",
    "X_test_fixed = X_test_sampler.sample(10)\n",
    "Y_test_fixed = Y_test_sampler.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plot_images(X_fixed, Y_fixed, T)\n",
    "fig, axes = plot_random_images(X_sampler, Y_sampler, T)\n",
    "fig, axes = plot_images(X_test_fixed, Y_test_fixed, T)\n",
    "fig, axes = plot_random_images(X_test_sampler, Y_test_sampler, T)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(name=EXP_NAME, project='snot', entity='dstech', config=config)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_opt = torch.optim.Adam(T.parameters(), lr=T_LR, weight_decay=1e-10)\n",
    "f_opt = torch.optim.Adam(f.parameters(), lr=f_LR, weight_decay=1e-10)\n",
    "\n",
    "training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finish experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finish experiment\n",
    "gc.collect(); torch.cuda.empty_cache()\n",
    "wandb.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking #2\n",
    "This Stacking-stage can be duplicated to continue stacking, if it is necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make prediction\n",
    "\n",
    "According to obtained FID-metric choose preferable step (for example, with minimal FID-metric) and save weights *\"0_[preferable step].pt*\" from checkpoints as *\"best_weights/stage_[STAGE].pt\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STAGE = 2\n",
    "\n",
    "# Only for stage 1, before getting the prediction\n",
    "# DATASET1_SOURCE_PATH = 'data/handbag_64.hdf5'\n",
    "\n",
    "# For the next stages (STAGE > 1)\n",
    "DATASET1_SOURCE_TRAIN_PATH =  f'data/handbag_64_train_stage_{STAGE-1}.pt'\n",
    "DATASET1_SOURCE_TEST_PATH =  f'data/handbag_64_test_stage_{STAGE-1}.pt'\n",
    "\n",
    "# Path for getting the best weights from last stage\n",
    "BEST_WEIGHTS_PATH = f'best_weights/stage_{STAGE-1}.pt'\n",
    "\n",
    "# Path for saving prediction images by the previous stage\n",
    "# and for loading from them for the current stage\n",
    "DATASET1_TRAIN_PATH = f'data/handbag_64_train_stage_{STAGE}.pt'\n",
    "DATASET1_TEST_PATH = f'data/handbag_64_test_stage_{STAGE}.pt'\n",
    "\n",
    "MAX_STEPS = 501 # for testing one-notebook solution, default = 30_001\n",
    "\n",
    "EXP_NAME = f'_{DATASET1}_{DATASET2}_T{T_ITERS}_{COST}_{IMG_SIZE}_S{STAGE}'\n",
    "OUTPUT_PATH = f'checkpoints/{COST}/{DATASET1}_{DATASET2}_{IMG_SIZE}/stage_{STAGE}'\n",
    "\n",
    "if not os.path.exists(OUTPUT_PATH):\n",
    "    os.makedirs(OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Previous Sampler X, if it is not on the RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For the stage 2 and next\n",
    "# X_sampler = new_sample_the_same(DATASET1_SOURCE_TRAIN_PATH)\n",
    "# X_test_sampler = new_sample_the_same(DATASET1_SOURCE_TEST_PATH)\n",
    "    \n",
    "# torch.cuda.empty_cache(); gc.collect()\n",
    "# # clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up T(X) on best weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = UNet(3, 3, base_factor=48)\n",
    "\n",
    "print('T params:', np.sum([np.prod(p.shape) for p in T.parameters()]))\n",
    "\n",
    "# Setup earlier params\n",
    "T.load_state_dict(torch.load(BEST_WEIGHTS_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on best T(X) for train and test, and save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_data(X_sampler, DATASET1_TRAIN_PATH, T)\n",
    "del X_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_data(X_test_sampler, DATASET1_TEST_PATH, T)\n",
    "del X_test_sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare New Samplers X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sampler = new_sample_the_same(DATASET1_TRAIN_PATH, shuffle=True)\n",
    "X_test_sampler = new_sample_the_same(DATASET1_TEST_PATH)\n",
    "\n",
    "torch.cuda.empty_cache(); gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = ResNet_D(IMG_SIZE, nc=3).cuda()\n",
    "f.apply(weights_init_D)\n",
    "\n",
    "T = UNet(3, 3, base_factor=48).cuda()\n",
    "\n",
    "if len(DEVICE_IDS) > 1:\n",
    "    T = nn.DataParallel(T, device_ids=DEVICE_IDS)\n",
    "    f = nn.DataParallel(f, device_ids=DEVICE_IDS)\n",
    "    \n",
    "print('T params:', np.sum([np.prod(p.shape) for p in T.parameters()]))\n",
    "print('f params:', np.sum([np.prod(p.shape) for p in f.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0xBADBEEF); np.random.seed(0xBADBEEF)\n",
    "X_fixed = X_sampler.sample(10)\n",
    "Y_fixed = Y_sampler.sample(10)\n",
    "X_test_fixed = X_test_sampler.sample(10)\n",
    "Y_test_fixed = Y_test_sampler.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plot_images(X_fixed, Y_fixed, T)\n",
    "fig, axes = plot_random_images(X_sampler, Y_sampler, T)\n",
    "fig, axes = plot_images(X_test_fixed, Y_test_fixed, T)\n",
    "fig, axes = plot_random_images(X_test_sampler, Y_test_sampler, T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(name=EXP_NAME, project='snot', entity='dstech', config=config)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_opt = torch.optim.Adam(T.parameters(), lr=T_LR, weight_decay=1e-10)\n",
    "f_opt = torch.optim.Adam(f.parameters(), lr=f_LR, weight_decay=1e-10)\n",
    "\n",
    "training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finish experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finish experiment\n",
    "gc.collect(); torch.cuda.empty_cache()\n",
    "wandb.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So 3 Stacking-like experiments were carried out. See the results in wandb (where you logged them)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
