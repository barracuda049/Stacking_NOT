{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import gc\n",
    "\n",
    "from src import distributions\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from src.resnet2 import ResNet_D\n",
    "from src.unet import UNet\n",
    "\n",
    "from src.tools import unfreeze, freeze\n",
    "from src.tools import weights_init_D\n",
    "from src.tools import load_dataset, get_pushed_loader_stats\n",
    "from src.fid_score import calculate_frechet_distance\n",
    "from src.plotters import plot_random_images, plot_images\n",
    "\n",
    "from copy import deepcopy\n",
    "import json\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import wandb # <--- online logging of the results\n",
    "from src.tools import fig2data, fig2img # for wandb\n",
    "\n",
    "# This needed to use dataloaders for some datasets\n",
    "from PIL import PngImagePlugin\n",
    "LARGE_ENOUGH_NUMBER = 100\n",
    "PngImagePlugin.MAX_TEXT_CHUNK = LARGE_ENOUGH_NUMBER * (1024**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "DEVICE_IDS = [0]\n",
    "\n",
    "DATASET1, DATASET1_PATH = 'handbag', '../../data/handbag_128.hdf5'\n",
    "DATASET2, DATASET2_PATH = 'shoes', '../../data/shoes_128.hdf5'\n",
    "\n",
    "# DATASET1, DATASET1_PATH = 'celeba_female', '../../data/img_align_celeba'\n",
    "# DATASET2, DATASET2_PATH = 'aligned_anime_faces', '../../data/aligned_anime_faces'\n",
    "\n",
    "T_ITERS = 10\n",
    "f_LR, T_LR = 1e-4, 1e-4\n",
    "IMG_SIZE = 64\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "PLOT_INTERVAL = 100\n",
    "COST = 'mse' # Mean Squared Error\n",
    "CPKT_INTERVAL = 2000\n",
    "MAX_STEPS = 100001\n",
    "SEED = 0x000000\n",
    "\n",
    "EXP_NAME = f'{DATASET1}_{DATASET2}_T{T_ITERS}_{COST}_{IMG_SIZE}'\n",
    "OUTPUT_PATH = '../checkpoints/{}/{}_{}_{}/'.format(COST, DATASET1, DATASET2, IMG_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    DATASET1=DATASET1,\n",
    "    DATASET2=DATASET2, \n",
    "    T_ITERS=T_ITERS,\n",
    "    f_LR=f_LR, T_LR=T_LR,\n",
    "    BATCH_SIZE=BATCH_SIZE\n",
    ")\n",
    "    \n",
    "assert torch.cuda.is_available()\n",
    "torch.cuda.set_device(f'cuda:{DEVICE_IDS[0]}')\n",
    "torch.manual_seed(SEED); np.random.seed(SEED)\n",
    "\n",
    "if not os.path.exists(OUTPUT_PATH):\n",
    "    os.makedirs(OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data stats for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../stats/{}_{}_test.json'.format(DATASET2, IMG_SIZE)\n",
    "with open(filename, 'r') as fp:\n",
    "    data_stats = json.load(fp)\n",
    "    mu_data, sigma_data = data_stats['mu'], data_stats['sigma']\n",
    "del data_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Samplers (X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sampler, X_test_sampler = load_dataset(DATASET1, DATASET1_PATH, img_size=IMG_SIZE)\n",
    "Y_sampler, Y_test_sampler = load_dataset(DATASET2, DATASET2_PATH, img_size=IMG_SIZE)\n",
    "    \n",
    "torch.cuda.empty_cache(); gc.collect()\n",
    "# clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = ResNet_D(IMG_SIZE, nc=3).cuda()\n",
    "f.apply(weights_init_D)\n",
    "\n",
    "T = UNet(3, 3, base_factor=48).cuda()\n",
    "\n",
    "if len(DEVICE_IDS) > 1:\n",
    "    T = nn.DataParallel(T, device_ids=DEVICE_IDS)\n",
    "    f = nn.DataParallel(f, device_ids=DEVICE_IDS)\n",
    "    \n",
    "print('T params:', np.sum([np.prod(p.shape) for p in T.parameters()]))\n",
    "print('f params:', np.sum([np.prod(p.shape) for p in f.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0xBADBEEF); np.random.seed(0xBADBEEF)\n",
    "X_fixed = X_sampler.sample(10)\n",
    "Y_fixed = Y_sampler.sample(10)\n",
    "X_test_fixed = X_test_sampler.sample(10)\n",
    "Y_test_fixed = Y_test_sampler.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plot_images(X_fixed, Y_fixed, T)\n",
    "fig, axes = plot_random_images(X_sampler, Y_sampler, T)\n",
    "fig, axes = plot_images(X_test_fixed, Y_test_fixed, T)\n",
    "fig, axes = plot_random_images(X_test_sampler, Y_test_sampler, T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(name=EXP_NAME, project='notreallyweakot', entity='gunsandroses', config=config)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_opt = torch.optim.Adam(T.parameters(), lr=T_LR, weight_decay=1e-10)\n",
    "f_opt = torch.optim.Adam(f.parameters(), lr=f_LR, weight_decay=1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for step in tqdm(range(MAX_STEPS)):\n",
    "    # T optimization\n",
    "    unfreeze(T); freeze(f)\n",
    "    for t_iter in range(T_ITERS): \n",
    "        T_opt.zero_grad()\n",
    "        X = X_sampler.sample(BATCH_SIZE)\n",
    "        T_X = T(X)\n",
    "        if COST == 'mse':\n",
    "            T_loss = F.mse_loss(X, T_X).mean() - f(T_X).mean()\n",
    "        else:\n",
    "            raise Exception('Unknown COST')\n",
    "        T_loss.backward(); T_opt.step()\n",
    "    del T_loss, T_X, X; gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "    # f optimization\n",
    "    freeze(T); unfreeze(f)\n",
    "    X = X_sampler.sample(BATCH_SIZE)\n",
    "    with torch.no_grad():\n",
    "        T_X = T(X)\n",
    "    Y = Y_sampler.sample(BATCH_SIZE)\n",
    "    f_opt.zero_grad()\n",
    "    f_loss = f(T_X).mean() - f(Y).mean()\n",
    "    f_loss.backward(); f_opt.step();\n",
    "    wandb.log({f'f_loss' : f_loss.item()}, step=step) \n",
    "    del f_loss, Y, X, T_X; gc.collect(); torch.cuda.empty_cache()\n",
    "        \n",
    "    if step % PLOT_INTERVAL == 0:\n",
    "        print('Plotting')\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        fig, axes = plot_images(X_fixed, Y_fixed, T)\n",
    "        wandb.log({'Fixed Images' : [wandb.Image(fig2img(fig))]}, step=step) \n",
    "        plt.show(fig); plt.close(fig) \n",
    "        \n",
    "        fig, axes = plot_random_images(X_sampler,  Y_sampler, T)\n",
    "        wandb.log({'Random Images' : [wandb.Image(fig2img(fig))]}, step=step) \n",
    "        plt.show(fig); plt.close(fig) \n",
    "        \n",
    "        fig, axes = plot_images(X_test_fixed, Y_test_fixed, T)\n",
    "        wandb.log({'Fixed Test Images' : [wandb.Image(fig2img(fig))]}, step=step) \n",
    "        plt.show(fig); plt.close(fig) \n",
    "        \n",
    "        fig, axes = plot_random_images(X_test_sampler, Y_test_sampler, T)\n",
    "        wandb.log({'Random Test Images' : [wandb.Image(fig2img(fig))]}, step=step) \n",
    "        plt.show(fig); plt.close(fig) \n",
    "    \n",
    "    if step % CPKT_INTERVAL == CPKT_INTERVAL - 1:\n",
    "        freeze(T); \n",
    "        \n",
    "        print('Computing FID')\n",
    "        mu, sigma = get_pushed_loader_stats(T, X_test_sampler.loader)\n",
    "        fid = calculate_frechet_distance(mu_data, sigma_data, mu, sigma)\n",
    "        wandb.log({f'FID (Test)' : fid}, step=step)\n",
    "        del mu, sigma\n",
    "        \n",
    "        torch.save(T.state_dict(), os.path.join(OUTPUT_PATH, f'{SEED}_{step}.pt'))\n",
    "#         torch.save(f.state_dict(), os.path.join(OUTPUT_PATH, f'f_{SEED}_{step}.pt'))\n",
    "#         torch.save(f_opt.state_dict(), os.path.join(OUTPUT_PATH, f'f_opt_{SEED}_{step}.pt'))\n",
    "#         torch.save(T_opt.state_dict(), os.path.join(OUTPUT_PATH, f'T_opt_{SEED}_{step}.pt'))\n",
    "    \n",
    "    gc.collect(); torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
